{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "nlp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "buko5NuUASih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNfpzZvAAa4-",
        "colab_type": "code",
        "outputId": "22e67df9-5945-477c-d1a3-d6b3d9c88875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_Z9J6QJAeXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk68jkJAASil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/fsog.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja-RJSBmASio",
        "colab_type": "code",
        "outputId": "702bd2db-287d-47bc-e159-422690fc499d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(text[:665])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chapter One \n",
            "\n",
            "I scowl with frustration at myself in the mirror. Damn my hair - it just won’t behave, \n",
            "and damn Katherine Kavanagh for being ill and subjecting me to this ordeal. I should be \n",
            "studying for my final exams, which are next week, yet here I am trying to brush my hair \n",
            "into submission. I must not sleep with it wet. I must not sleep with it wet. Reciting this \n",
            "mantra several times, I attempt, once more, to bring it under control with the brush. I roll \n",
            "my eyes in exasperation and gaze at the pale, brown-haired girl with blue eyes too big for \n",
            "her face staring back at me, and give up. My only option is to restrain my wayward hair in \n",
            "a ponytail and \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpJD6LFMASir",
        "colab_type": "code",
        "outputId": "c11e0e2e-41cb-4087-92b4-9a3a2dfce1c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "unique_characters = set(text)\n",
        "print(f\"Number of unique characters: {unique_characters}\\n\\nLength: {len(unique_characters)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique characters: {'h', ' ', 'v', '?', 'm', 'P', ')', 'e', '!', 'Z', '&', '1', '+', '”', 'j', 'q', ',', '^', 'Q', 'R', ']', 'z', 'n', '6', 'U', 'A', 'p', '-', 'a', '©', 'g', '2', 'H', '9', '—', 't', '$', '(', ':', 'M', 'f', '0', 'C', 'r', 'i', '|', '7', 'o', '\\n', 'y', '>', 'E', 'D', 'B', '~', 'Y', 'u', 'F', 'k', '/', '_', '*', 'W', '8', '5', 'J', '[', 'w', '.', 'l', 'x', 'N', 'T', '“', 'O', '’', '\"', '\\\\', \"'\", 'd', 'K', 'X', '4', 'V', 'L', 'c', 's', 'I', ';', 'b', '3', '■', '‘', '•', 'G', 'S'}\n",
            "\n",
            "Length: 96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc2ngNF8ASiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder = dict(enumerate(unique_characters))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_av0WA2ASix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = {char: index for index, char in decoder.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAwG8Lq6ASi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_text = np.array([encoder[char] for char in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "8N9wDwMSASi3",
        "colab_type": "code",
        "outputId": "bdcc099e-7d60-40ef-89ad-8497fea9449f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "print(encoded_text[:500])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[42  0 28 26 35  7 43  1 74 22  7  1 48 48 87  1 86 85 47 67 69  1 67 44\n",
            " 35  0  1 40 43 56 86 35 43 28 35 44 47 22  1 28 35  1  4 49 86  7 69 40\n",
            "  1 44 22  1 35  0  7  1  4 44 43 43 47 43 68  1 52 28  4 22  1  4 49  1\n",
            "  0 28 44 43  1 27  1 44 35  1 14 56 86 35  1 67 47 22 75 35  1 89  7  0\n",
            " 28  2  7 16  1 48 28 22 79  1 79 28  4 22  1 80 28 35  0  7 43 44 22  7\n",
            "  1 80 28  2 28 22 28 30  0  1 40 47 43  1 89  7 44 22 30  1 44 69 69  1\n",
            " 28 22 79  1 86 56 89 14  7 85 35 44 22 30  1  4  7  1 35 47  1 35  0 44\n",
            " 86  1 47 43 79  7 28 69 68  1 87  1 86  0 47 56 69 79  1 89  7  1 48 86\n",
            " 35 56 79 49 44 22 30  1 40 47 43  1  4 49  1 40 44 22 28 69  1  7 70 28\n",
            "  4 86 16  1 67  0 44 85  0  1 28 43  7  1 22  7 70 35  1 67  7  7 58 16\n",
            "  1 49  7 35  1  0  7 43  7  1 87  1 28  4  1 35 43 49 44 22 30  1 35 47\n",
            "  1 89 43 56 86  0  1  4 49  1  0 28 44 43  1 48 44 22 35 47  1 86 56 89\n",
            "  4 44 86 86 44 47 22 68  1 87  1  4 56 86 35  1 22 47 35  1 86 69  7  7\n",
            " 26  1 67 44 35  0  1 44 35  1 67  7 35 68  1 87  1  4 56 86 35  1 22 47\n",
            " 35  1 86 69  7  7 26  1 67 44 35  0  1 44 35  1 67  7 35 68  1 19  7 85\n",
            " 44 35 44 22 30  1 35  0 44 86  1 48  4 28 22 35 43 28  1 86  7  2  7 43\n",
            " 28 69  1 35 44  4  7 86 16  1 87  1 28 35 35  7  4 26 35 16  1 47 22 85\n",
            "  7  1  4 47 43  7 16  1 35 47  1 89 43 44 22 30  1 44 35  1 56 22 79  7\n",
            " 43  1 85 47 22 35 43 47 69  1 67 44 35  0  1 35  0  7  1 89 43 56 86  0\n",
            " 68  1 87  1 43 47 69 69  1 48  4 49  1  7 49  7 86  1 44 22  1  7 70 28\n",
            " 86 26  7 43 28 35 44 47 22  1 28 22 79  1 30 28 21  7  1 28]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPSogPdE4tnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/fsog_decoder.dat', 'wb') as f:\n",
        "  pickle.dump(decoder, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYBCHyaO47KJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/fsog_encoder.dat', 'wb') as f:\n",
        "  pickle.dump(encoder, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQdituXzASi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_encoder(encoded_text, nunique):\n",
        "    one_hot = np.zeros((encoded_text.size, nunique))\n",
        "    one_hot = one_hot.astype(np.float32)\n",
        "    one_hot[np.arange(one_hot.shape[0]), encoded_text.flatten()] = 1.0\n",
        "    one_hot = one_hot.reshape((*encoded_text.shape, nunique))\n",
        "    return one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK8oaminASi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_batches(encoded_text, batch_size=10, sequence_length=50):\n",
        "    num_chars = batch_size * sequence_length\n",
        "    num_batches = int(len(encoded_text)/num_chars)\n",
        "    \n",
        "    encoded_text = encoded_text[:num_batches*num_chars]\n",
        "    \n",
        "    encoded_text = encoded_text.reshape((batch_size, -1))\n",
        "    \n",
        "    for n in range(0, encoded_text.shape[1], sequence_length):\n",
        "        x = encoded_text[:, n:n+sequence_length]\n",
        "        y = np.zeros_like(x)\n",
        "        \n",
        "        try:\n",
        "            y[:, :-1] = x[:, 1:]\n",
        "            y[:, -1] = encoded_text[:, n+sequence_length]\n",
        "        except:\n",
        "            y[:, :-1] = x[:, 1:]\n",
        "            y[:, -1] = encoded_text[:, 0]\n",
        "        \n",
        "        yield x, y "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_47i02vASjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GenerativeModel(nn.Module):\n",
        "    def __init__(self, total_chars, hidden_size=256, num_layers=4, p=0.5, cuda=False):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.num_layers= num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.use_cuda = cuda\n",
        "        \n",
        "        self.total_chars = total_chars\n",
        "        self.decoder = dict(enumerate(self.total_chars))\n",
        "        self.encoder = {char: index for index, char in self.decoder.items()}\n",
        "        \n",
        "        self.char_len = len(self.total_chars)\n",
        "        \n",
        "        self.lstm = nn.LSTM(self.char_len, self.hidden_size, self.num_layers, dropout=p, batch_first=True)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p)\n",
        "        \n",
        "        self.fc1 = nn.Linear(self.hidden_size, self.char_len)\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        out, hidden = self.lstm(x, hidden)\n",
        "        \n",
        "        out = self.dropout(out)\n",
        "        \n",
        "        out = out.contiguous().view(-1, self.hidden_size)\n",
        "        \n",
        "        out = self.fc1(out)\n",
        "        \n",
        "        return out, hidden\n",
        "    \n",
        "    def hidden_state(self, batch_size):\n",
        "        if self.use_cuda:\n",
        "            hidden = (torch.zeros(self.num_layers, batch_size, self.hidden_size).cuda(), torch.zeros(self.num_layers, batch_size, self.hidden_size).cuda())\n",
        "        \n",
        "        else:\n",
        "            hidden = (torch.zeros(self.num_layers, batch_size, self.hidden_size), torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
        "\n",
        "        return hidden    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmTVFqn9ASjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = GenerativeModel(total_chars=unique_characters, hidden_size=512, num_layers=4, p=0.4, cuda=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAM48P17ASjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_percent = 0.9\n",
        "train_index = int(len(encoded_text) * train_percent)\n",
        "train_data = encoded_text[:train_index]\n",
        "test_data = encoded_text[train_index:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp-eVAjZASjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "epochs = 60\n",
        "batch_size = 64\n",
        "sequence_length = 100\n",
        "num_char = max(encoded_text) + 1\n",
        "t = 0 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tbhMSjmkASjK",
        "colab_type": "code",
        "outputId": "247727fa-a526-44d8-f3d0-75d406faa120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.train()\n",
        "\n",
        "if model.use_cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for i in range(epochs):\n",
        "    e_start = time.time()\n",
        "    \n",
        "    hidden = model.hidden_state(batch_size)\n",
        "    \n",
        "    for x, y in create_batches(train_data, batch_size, sequence_length):\n",
        "        t += 1\n",
        "        \n",
        "        x = one_hot_encoder(x, num_char)\n",
        "        \n",
        "        inputs = torch.from_numpy(x)\n",
        "        targets = torch.from_numpy(y)\n",
        "        \n",
        "        if model.use_cuda:\n",
        "            inputs = inputs.cuda()\n",
        "            targets = targets.cuda()\n",
        "        \n",
        "        hidden = tuple([state.data for state in hidden])\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        lstm_output, hidden = model.forward(inputs, hidden)\n",
        "        loss = criterion(lstm_output, targets.view(batch_size*sequence_length).long())\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        if t % 50 == 0:\n",
        "            e_end = time.time() - e_start\n",
        "            val_hidden = model.hidden_state(batch_size)\n",
        "            val_losses = []\n",
        "            model.eval()\n",
        "            \n",
        "            for x, y in create_batches(test_data, batch_size, sequence_length):\n",
        "                x = one_hot_encoder(x, num_char)\n",
        "        \n",
        "                inputs = torch.from_numpy(x)\n",
        "                targets = torch.from_numpy(y)\n",
        "\n",
        "                if model.use_cuda:\n",
        "                    inputs = inputs.cuda()\n",
        "                    targets = targets.cuda()\n",
        "                    \n",
        "                val_hidden = tuple([state.data for state in hidden])\n",
        "                \n",
        "                lstm_out, val_hidden = model.forward(inputs, val_hidden)\n",
        "                val_loss = criterion(lstm_out, targets.view(batch_size * sequence_length).long())\n",
        "                val_losses.append(val_loss.item())\n",
        "            \n",
        "            model.train()\n",
        "            \n",
        "            print(f\"Epoch {i+1}\\nLoss: {loss.item():.4f} | Validation Loss: {val_loss.item():.4f} | Duration: {e_end/60:.2f} minutes\")\n",
        "           \n",
        "end_time = time.time() - start_time\n",
        "print(f\"\\nTotal Training Duration {end_time/60:.2f}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "Loss: 3.2173 | Validation Loss: 3.1673 | Duration: 0.12 minutes\n",
            "Epoch 1\n",
            "Loss: 3.2407 | Validation Loss: 3.1682 | Duration: 0.24 minutes\n",
            "Epoch 2\n",
            "Loss: 3.1947 | Validation Loss: 3.1661 | Duration: 0.07 minutes\n",
            "Epoch 2\n",
            "Loss: 3.2041 | Validation Loss: 3.1664 | Duration: 0.20 minutes\n",
            "Epoch 3\n",
            "Loss: 3.1985 | Validation Loss: 3.1655 | Duration: 0.03 minutes\n",
            "Epoch 3\n",
            "Loss: 3.1992 | Validation Loss: 3.1650 | Duration: 0.16 minutes\n",
            "Epoch 3\n",
            "Loss: 3.1422 | Validation Loss: 3.1638 | Duration: 0.28 minutes\n",
            "Epoch 4\n",
            "Loss: 3.1520 | Validation Loss: 3.1623 | Duration: 0.11 minutes\n",
            "Epoch 4\n",
            "Loss: 3.1773 | Validation Loss: 3.1453 | Duration: 0.23 minutes\n",
            "Epoch 5\n",
            "Loss: 2.8405 | Validation Loss: 2.7904 | Duration: 0.07 minutes\n",
            "Epoch 5\n",
            "Loss: 2.6333 | Validation Loss: 2.6049 | Duration: 0.19 minutes\n",
            "Epoch 6\n",
            "Loss: 2.4961 | Validation Loss: 2.4431 | Duration: 0.02 minutes\n",
            "Epoch 6\n",
            "Loss: 2.3648 | Validation Loss: 2.3438 | Duration: 0.15 minutes\n",
            "Epoch 6\n",
            "Loss: 2.3236 | Validation Loss: 2.2810 | Duration: 0.27 minutes\n",
            "Epoch 7\n",
            "Loss: 2.2492 | Validation Loss: 2.2293 | Duration: 0.10 minutes\n",
            "Epoch 7\n",
            "Loss: 2.2237 | Validation Loss: 2.1898 | Duration: 0.22 minutes\n",
            "Epoch 8\n",
            "Loss: 2.2064 | Validation Loss: 2.1437 | Duration: 0.06 minutes\n",
            "Epoch 8\n",
            "Loss: 2.1423 | Validation Loss: 2.1062 | Duration: 0.18 minutes\n",
            "Epoch 9\n",
            "Loss: 2.1255 | Validation Loss: 2.0766 | Duration: 0.01 minutes\n",
            "Epoch 9\n",
            "Loss: 2.0961 | Validation Loss: 2.0464 | Duration: 0.14 minutes\n",
            "Epoch 9\n",
            "Loss: 2.0674 | Validation Loss: 2.0196 | Duration: 0.26 minutes\n",
            "Epoch 10\n",
            "Loss: 1.9964 | Validation Loss: 1.9767 | Duration: 0.09 minutes\n",
            "Epoch 10\n",
            "Loss: 1.9732 | Validation Loss: 1.9661 | Duration: 0.21 minutes\n",
            "Epoch 11\n",
            "Loss: 1.9732 | Validation Loss: 1.9327 | Duration: 0.05 minutes\n",
            "Epoch 11\n",
            "Loss: 1.9588 | Validation Loss: 1.9118 | Duration: 0.17 minutes\n",
            "Epoch 12\n",
            "Loss: 1.9328 | Validation Loss: 1.8884 | Duration: 0.00 minutes\n",
            "Epoch 12\n",
            "Loss: 1.9119 | Validation Loss: 1.8809 | Duration: 0.13 minutes\n",
            "Epoch 12\n",
            "Loss: 1.8930 | Validation Loss: 1.8489 | Duration: 0.25 minutes\n",
            "Epoch 13\n",
            "Loss: 1.8593 | Validation Loss: 1.8330 | Duration: 0.08 minutes\n",
            "Epoch 13\n",
            "Loss: 1.8740 | Validation Loss: 1.8147 | Duration: 0.20 minutes\n",
            "Epoch 14\n",
            "Loss: 1.8377 | Validation Loss: 1.8003 | Duration: 0.04 minutes\n",
            "Epoch 14\n",
            "Loss: 1.8369 | Validation Loss: 1.7789 | Duration: 0.16 minutes\n",
            "Epoch 14\n",
            "Loss: 1.7602 | Validation Loss: 1.7819 | Duration: 0.29 minutes\n",
            "Epoch 15\n",
            "Loss: 1.8215 | Validation Loss: 1.7543 | Duration: 0.11 minutes\n",
            "Epoch 15\n",
            "Loss: 1.7814 | Validation Loss: 1.7445 | Duration: 0.24 minutes\n",
            "Epoch 16\n",
            "Loss: 1.7909 | Validation Loss: 1.7276 | Duration: 0.07 minutes\n",
            "Epoch 16\n",
            "Loss: 1.6993 | Validation Loss: 1.7183 | Duration: 0.20 minutes\n",
            "Epoch 17\n",
            "Loss: 1.7306 | Validation Loss: 1.7104 | Duration: 0.03 minutes\n",
            "Epoch 17\n",
            "Loss: 1.7218 | Validation Loss: 1.6928 | Duration: 0.15 minutes\n",
            "Epoch 17\n",
            "Loss: 1.7268 | Validation Loss: 1.6863 | Duration: 0.28 minutes\n",
            "Epoch 18\n",
            "Loss: 1.7345 | Validation Loss: 1.6749 | Duration: 0.10 minutes\n",
            "Epoch 18\n",
            "Loss: 1.6746 | Validation Loss: 1.6691 | Duration: 0.23 minutes\n",
            "Epoch 19\n",
            "Loss: 1.7216 | Validation Loss: 1.6526 | Duration: 0.06 minutes\n",
            "Epoch 19\n",
            "Loss: 1.6385 | Validation Loss: 1.6460 | Duration: 0.19 minutes\n",
            "Epoch 20\n",
            "Loss: 1.6561 | Validation Loss: 1.6372 | Duration: 0.02 minutes\n",
            "Epoch 20\n",
            "Loss: 1.6217 | Validation Loss: 1.6381 | Duration: 0.14 minutes\n",
            "Epoch 20\n",
            "Loss: 1.6948 | Validation Loss: 1.6173 | Duration: 0.27 minutes\n",
            "Epoch 21\n",
            "Loss: 1.6386 | Validation Loss: 1.6056 | Duration: 0.09 minutes\n",
            "Epoch 21\n",
            "Loss: 1.6742 | Validation Loss: 1.6034 | Duration: 0.22 minutes\n",
            "Epoch 22\n",
            "Loss: 1.5942 | Validation Loss: 1.5935 | Duration: 0.05 minutes\n",
            "Epoch 22\n",
            "Loss: 1.6036 | Validation Loss: 1.5939 | Duration: 0.18 minutes\n",
            "Epoch 23\n",
            "Loss: 1.5758 | Validation Loss: 1.5795 | Duration: 0.01 minutes\n",
            "Epoch 23\n",
            "Loss: 1.5533 | Validation Loss: 1.5800 | Duration: 0.13 minutes\n",
            "Epoch 23\n",
            "Loss: 1.5227 | Validation Loss: 1.5874 | Duration: 0.26 minutes\n",
            "Epoch 24\n",
            "Loss: 1.5498 | Validation Loss: 1.5668 | Duration: 0.08 minutes\n",
            "Epoch 24\n",
            "Loss: 1.6278 | Validation Loss: 1.5650 | Duration: 0.21 minutes\n",
            "Epoch 25\n",
            "Loss: 1.5379 | Validation Loss: 1.5616 | Duration: 0.04 minutes\n",
            "Epoch 25\n",
            "Loss: 1.5505 | Validation Loss: 1.5433 | Duration: 0.17 minutes\n",
            "Epoch 25\n",
            "Loss: 1.6118 | Validation Loss: 1.5518 | Duration: 0.29 minutes\n",
            "Epoch 26\n",
            "Loss: 1.5426 | Validation Loss: 1.5354 | Duration: 0.12 minutes\n",
            "Epoch 26\n",
            "Loss: 1.5246 | Validation Loss: 1.5500 | Duration: 0.24 minutes\n",
            "Epoch 27\n",
            "Loss: 1.5340 | Validation Loss: 1.5203 | Duration: 0.08 minutes\n",
            "Epoch 27\n",
            "Loss: 1.4873 | Validation Loss: 1.5171 | Duration: 0.20 minutes\n",
            "Epoch 28\n",
            "Loss: 1.4761 | Validation Loss: 1.5201 | Duration: 0.03 minutes\n",
            "Epoch 28\n",
            "Loss: 1.5170 | Validation Loss: 1.5127 | Duration: 0.16 minutes\n",
            "Epoch 28\n",
            "Loss: 1.5155 | Validation Loss: 1.5025 | Duration: 0.28 minutes\n",
            "Epoch 29\n",
            "Loss: 1.5172 | Validation Loss: 1.4917 | Duration: 0.11 minutes\n",
            "Epoch 29\n",
            "Loss: 1.4483 | Validation Loss: 1.5146 | Duration: 0.23 minutes\n",
            "Epoch 30\n",
            "Loss: 1.4845 | Validation Loss: 1.4847 | Duration: 0.07 minutes\n",
            "Epoch 30\n",
            "Loss: 1.4918 | Validation Loss: 1.4804 | Duration: 0.19 minutes\n",
            "Epoch 31\n",
            "Loss: 1.4722 | Validation Loss: 1.4875 | Duration: 0.02 minutes\n",
            "Epoch 31\n",
            "Loss: 1.4506 | Validation Loss: 1.4901 | Duration: 0.15 minutes\n",
            "Epoch 31\n",
            "Loss: 1.4949 | Validation Loss: 1.4685 | Duration: 0.27 minutes\n",
            "Epoch 32\n",
            "Loss: 1.4644 | Validation Loss: 1.4749 | Duration: 0.10 minutes\n",
            "Epoch 32\n",
            "Loss: 1.4497 | Validation Loss: 1.4768 | Duration: 0.22 minutes\n",
            "Epoch 33\n",
            "Loss: 1.4699 | Validation Loss: 1.4736 | Duration: 0.06 minutes\n",
            "Epoch 33\n",
            "Loss: 1.4182 | Validation Loss: 1.4582 | Duration: 0.18 minutes\n",
            "Epoch 34\n",
            "Loss: 1.4435 | Validation Loss: 1.4674 | Duration: 0.01 minutes\n",
            "Epoch 34\n",
            "Loss: 1.4305 | Validation Loss: 1.4638 | Duration: 0.14 minutes\n",
            "Epoch 34\n",
            "Loss: 1.4126 | Validation Loss: 1.4640 | Duration: 0.27 minutes\n",
            "Epoch 35\n",
            "Loss: 1.3802 | Validation Loss: 1.4354 | Duration: 0.09 minutes\n",
            "Epoch 35\n",
            "Loss: 1.3919 | Validation Loss: 1.4600 | Duration: 0.22 minutes\n",
            "Epoch 36\n",
            "Loss: 1.4026 | Validation Loss: 1.4489 | Duration: 0.05 minutes\n",
            "Epoch 36\n",
            "Loss: 1.4268 | Validation Loss: 1.4444 | Duration: 0.17 minutes\n",
            "Epoch 37\n",
            "Loss: 1.3956 | Validation Loss: 1.4364 | Duration: 0.00 minutes\n",
            "Epoch 37\n",
            "Loss: 1.4178 | Validation Loss: 1.4516 | Duration: 0.13 minutes\n",
            "Epoch 37\n",
            "Loss: 1.3827 | Validation Loss: 1.4311 | Duration: 0.26 minutes\n",
            "Epoch 38\n",
            "Loss: 1.3646 | Validation Loss: 1.4401 | Duration: 0.08 minutes\n",
            "Epoch 38\n",
            "Loss: 1.3987 | Validation Loss: 1.4359 | Duration: 0.21 minutes\n",
            "Epoch 39\n",
            "Loss: 1.3788 | Validation Loss: 1.4364 | Duration: 0.04 minutes\n",
            "Epoch 39\n",
            "Loss: 1.3976 | Validation Loss: 1.4250 | Duration: 0.16 minutes\n",
            "Epoch 39\n",
            "Loss: 1.3206 | Validation Loss: 1.4323 | Duration: 0.29 minutes\n",
            "Epoch 40\n",
            "Loss: 1.3941 | Validation Loss: 1.4263 | Duration: 0.11 minutes\n",
            "Epoch 40\n",
            "Loss: 1.3557 | Validation Loss: 1.4245 | Duration: 0.24 minutes\n",
            "Epoch 41\n",
            "Loss: 1.4074 | Validation Loss: 1.4204 | Duration: 0.07 minutes\n",
            "Epoch 41\n",
            "Loss: 1.3130 | Validation Loss: 1.4210 | Duration: 0.20 minutes\n",
            "Epoch 42\n",
            "Loss: 1.3370 | Validation Loss: 1.4260 | Duration: 0.03 minutes\n",
            "Epoch 42\n",
            "Loss: 1.3465 | Validation Loss: 1.4266 | Duration: 0.15 minutes\n",
            "Epoch 42\n",
            "Loss: 1.3739 | Validation Loss: 1.4283 | Duration: 0.28 minutes\n",
            "Epoch 43\n",
            "Loss: 1.3765 | Validation Loss: 1.4087 | Duration: 0.10 minutes\n",
            "Epoch 43\n",
            "Loss: 1.3278 | Validation Loss: 1.4151 | Duration: 0.23 minutes\n",
            "Epoch 44\n",
            "Loss: 1.3855 | Validation Loss: 1.4186 | Duration: 0.06 minutes\n",
            "Epoch 44\n",
            "Loss: 1.2858 | Validation Loss: 1.4127 | Duration: 0.19 minutes\n",
            "Epoch 45\n",
            "Loss: 1.3254 | Validation Loss: 1.4154 | Duration: 0.02 minutes\n",
            "Epoch 45\n",
            "Loss: 1.2968 | Validation Loss: 1.4200 | Duration: 0.14 minutes\n",
            "Epoch 45\n",
            "Loss: 1.3793 | Validation Loss: 1.4101 | Duration: 0.27 minutes\n",
            "Epoch 46\n",
            "Loss: 1.3151 | Validation Loss: 1.3965 | Duration: 0.09 minutes\n",
            "Epoch 46\n",
            "Loss: 1.3401 | Validation Loss: 1.3996 | Duration: 0.22 minutes\n",
            "Epoch 47\n",
            "Loss: 1.3062 | Validation Loss: 1.4043 | Duration: 0.05 minutes\n",
            "Epoch 47\n",
            "Loss: 1.3152 | Validation Loss: 1.4053 | Duration: 0.18 minutes\n",
            "Epoch 48\n",
            "Loss: 1.2800 | Validation Loss: 1.3950 | Duration: 0.01 minutes\n",
            "Epoch 48\n",
            "Loss: 1.2752 | Validation Loss: 1.4048 | Duration: 0.14 minutes\n",
            "Epoch 48\n",
            "Loss: 1.2381 | Validation Loss: 1.4141 | Duration: 0.26 minutes\n",
            "Epoch 49\n",
            "Loss: 1.2933 | Validation Loss: 1.3972 | Duration: 0.08 minutes\n",
            "Epoch 49\n",
            "Loss: 1.3450 | Validation Loss: 1.4028 | Duration: 0.21 minutes\n",
            "Epoch 50\n",
            "Loss: 1.2700 | Validation Loss: 1.4134 | Duration: 0.04 minutes\n",
            "Epoch 50\n",
            "Loss: 1.2833 | Validation Loss: 1.3956 | Duration: 0.17 minutes\n",
            "Epoch 50\n",
            "Loss: 1.3608 | Validation Loss: 1.4183 | Duration: 0.29 minutes\n",
            "Epoch 51\n",
            "Loss: 1.2974 | Validation Loss: 1.3971 | Duration: 0.12 minutes\n",
            "Epoch 51\n",
            "Loss: 1.2855 | Validation Loss: 1.4170 | Duration: 0.24 minutes\n",
            "Epoch 52\n",
            "Loss: 1.2588 | Validation Loss: 1.3800 | Duration: 0.08 minutes\n",
            "Epoch 52\n",
            "Loss: 1.2539 | Validation Loss: 1.3929 | Duration: 0.20 minutes\n",
            "Epoch 53\n",
            "Loss: 1.2380 | Validation Loss: 1.3956 | Duration: 0.03 minutes\n",
            "Epoch 53\n",
            "Loss: 1.2767 | Validation Loss: 1.3963 | Duration: 0.16 minutes\n",
            "Epoch 53\n",
            "Loss: 1.2802 | Validation Loss: 1.3842 | Duration: 0.28 minutes\n",
            "Epoch 54\n",
            "Loss: 1.2801 | Validation Loss: 1.3795 | Duration: 0.11 minutes\n",
            "Epoch 54\n",
            "Loss: 1.2308 | Validation Loss: 1.4061 | Duration: 0.23 minutes\n",
            "Epoch 55\n",
            "Loss: 1.2759 | Validation Loss: 1.3744 | Duration: 0.07 minutes\n",
            "Epoch 55\n",
            "Loss: 1.2696 | Validation Loss: 1.3833 | Duration: 0.19 minutes\n",
            "Epoch 56\n",
            "Loss: 1.2561 | Validation Loss: 1.3829 | Duration: 0.02 minutes\n",
            "Epoch 56\n",
            "Loss: 1.2351 | Validation Loss: 1.3803 | Duration: 0.15 minutes\n",
            "Epoch 56\n",
            "Loss: 1.2863 | Validation Loss: 1.3715 | Duration: 0.28 minutes\n",
            "Epoch 57\n",
            "Loss: 1.2689 | Validation Loss: 1.3747 | Duration: 0.10 minutes\n",
            "Epoch 57\n",
            "Loss: 1.2486 | Validation Loss: 1.3892 | Duration: 0.22 minutes\n",
            "Epoch 58\n",
            "Loss: 1.2752 | Validation Loss: 1.3980 | Duration: 0.06 minutes\n",
            "Epoch 58\n",
            "Loss: 1.2312 | Validation Loss: 1.3728 | Duration: 0.18 minutes\n",
            "Epoch 59\n",
            "Loss: 1.2590 | Validation Loss: 1.3848 | Duration: 0.01 minutes\n",
            "Epoch 59\n",
            "Loss: 1.2422 | Validation Loss: 1.3870 | Duration: 0.14 minutes\n",
            "Epoch 59\n",
            "Loss: 1.2271 | Validation Loss: 1.4047 | Duration: 0.27 minutes\n",
            "Epoch 60\n",
            "Loss: 1.2018 | Validation Loss: 1.3578 | Duration: 0.09 minutes\n",
            "Epoch 60\n",
            "Loss: 1.2116 | Validation Loss: 1.3899 | Duration: 0.22 minutes\n",
            "\n",
            "Total Training Duration 17.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNGczo1JASjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), '/content/drive/My Drive/fsog.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB3y_48K5CFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/fsog_model_decoder.dat', 'wb') as f:\n",
        "  pickle.dump(model.decoder, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ7QGHos5Ckz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/fsog_model_encoder.dat', 'wb') as f:\n",
        "  pickle.dump(model.encoder, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYjI-Ur0ASjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_next_char(model, char, hidden=None, k=1):\n",
        "    encoded_text = model.encoder[char]\n",
        "    encoded_text = np.array([[encoded_text]])\n",
        "    encoded_text = one_hot_encoder(encoded_text, len(model.total_chars))\n",
        "    inputs = torch.from_numpy(encoded_text)\n",
        "    \n",
        "    if model.use_cuda:\n",
        "        inputs = inputs.cuda()\n",
        "    \n",
        "    hidden = tuple([state.data for state in hidden])\n",
        "    \n",
        "    out, hidden = model(inputs, hidden)\n",
        "    \n",
        "    probs = F.softmax(out, dim=1).data\n",
        "    \n",
        "    if model.use_cuda:\n",
        "        probs = probs.cpu()\n",
        "        \n",
        "    probs, index_pos = probs.topk(k)\n",
        "    \n",
        "    index_pos = index_pos.numpy().squeeze()\n",
        "    \n",
        "    probs = probs.numpy().flatten()\n",
        "    \n",
        "    probs = probs/probs.sum()\n",
        "    \n",
        "    next_char = np.random.choice(index_pos, p=probs)\n",
        "    \n",
        "    return model.decoder[next_char], hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzfJdth9ASjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, size, seed='I', k=1):\n",
        "    if model.use_cuda:\n",
        "        model = model.cuda()\n",
        "    else:\n",
        "        model = model.cpu()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    output_chars = [c for c in seed]\n",
        "    \n",
        "    hidden = model.hidden_state(1)\n",
        "    \n",
        "    for char in seed:\n",
        "        char, hidden = get_next_char(model, char, hidden, k=k)\n",
        "        \n",
        "    output_chars.append(char)\n",
        "    \n",
        "    for i in range(size):\n",
        "        char, hidden = get_next_char(model, output_chars[-1], hidden, k=k)\n",
        "        output_chars.append(char)\n",
        "    \n",
        "    return ''.join(output_chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_6Lu_MOASjU",
        "colab_type": "code",
        "outputId": "a2c43f43-e2e1-40b2-dd97-0fd6bf658c92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(generate_text(model, 500, seed='I', k=3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I he’s not sure I’m \n",
            "touching my hand and then softly. I shake my hand, and I can’t tell her. I want to stay, \n",
            "and I close my helicopter that the words, and I can’t hold my exaspears. I am not touched \n",
            "to many move, and he still draps my hand. He stares at me. “Well, this is \n",
            "shall with that about my stomach. I don’t want to say anything, and I’m \n",
            "too with that. Tomorrow and the moment,” I mutter. His tone is \n",
            "stranged and grasps my hand. \n",
            "\n",
            "“I’ve not going to stay.” He presses his explession in my\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8EHTioz-93X",
        "colab_type": "code",
        "outputId": "37af1146-7d2c-4e4c-8ad2-36f8c4ab728e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(generate_text(model, 500, seed='kill', k=10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kille what after I sit. It \n",
            "feels awoins from Christian caulot to know my head of times. I don’t want to hide. I \n",
            "don’t sit will be with me. Why he’ll have boter in his feet to some our arrungered. Come in a \n",
            "sweet talling thought makes them thrush between answer at shail of the fitting of trush with hard. I \n",
            "could say what’s not as is a deliberately. I scill one switch, and soft, and I don’t understand. \n",
            "\n",
            "He smiles about his tea and holding me suddenly. He’s still half to hard in the corred? \n",
            "\n",
            "\n",
            "“Wea\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm1AhjsrAc-B",
        "colab_type": "code",
        "outputId": "13bdd804-0352-4983-a6ec-6660c6716334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "print(generate_text(model, 500, seed='like', k=40))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "like, \n",
            "detjo-eting magor. I expressed in the right of. Add I’m close into my \n",
            "cboth - wink? Just only the onay under wime concertation to he - pleasen’t \n",
            "speen things to a push and clampes. I build night. \n",
            "\n",
            "“No.” I release my resiler thoughts through his ear unleashed, catical comfletely back to any \n",
            "long. \n",
            "\n",
            "“I’ll tell me what pushed it de. She’s horrided by your. My mother is really this yele. Maybe they’re company, then we’re entrackedly to \n",
            "trust me.” \n",
            "\n",
            "I hang as a very behind. You like the doow. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EznJ7xxHAz-v",
        "colab_type": "code",
        "outputId": "a2e77174-57a5-409d-8471-bda3fc2f713c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "print(generate_text(model, 1000, seed='pleasure', k=50))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pleasure? \n",
            "\n",
            "“Well, what I would like you, piils. Kate two start had away for you?” \n",
            "\n",
            "“You can tell him?” He smiles. \n",
            "\n",
            "“You later him?” I whisper. My skyterces of me But an undo- \n",
            "small moments there. I’m never seing to me, door, the soft of suctisualy moun-sudy \n",
            "forsal clamp is in My breath. She says her’s like this. Them want his things lot other \n",
            "this wait deep, and the long, books in decresting appolrant of there and \n",
            "the seven mine, but she leans down on between his phustration, staring from me. My thunging \n",
            "from the pursing confuser, and Christian pives crapily. Beens for a little fire he is he like that? \n",
            "\n",
            "“Ahais the time we’re love. So impecialAs? And about Paris, and I don’t think that \n",
            "only ne madness with you,” he says from the progeded. Bending, I shall \n",
            "whise this intitated sound. I recover to ask the kitchen, learing out of the arms and talking \n",
            "on the elevator elevant? She holds the black water, on all a smile, and \n",
            "not litten to reach my face. \n",
            "\n",
            "\n",
            "Christian and hesset the door, hi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7DKm0jzCwlV",
        "colab_type": "code",
        "outputId": "2681fc02-7f98-46a7-de12-e3dc7efae274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate_text(model, 10, seed='passion', k=50))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "passion he squeeze\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpLZXkkK3vKT",
        "colab_type": "code",
        "outputId": "6b6ee414-b11b-4630-b69e-ce5241801350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate_text(model, 10, seed='stop', k=50))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stopten, I ging\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}